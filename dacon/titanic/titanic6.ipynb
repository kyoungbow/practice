{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a13ab9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c4d7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data_files/train.csv')\n",
    "test = pd.read_csv('data_files/test.csv')\n",
    "sample_submission = pd.read_csv('data_files/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfb5f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['ID'], axis = 1)\n",
    "test = test.drop(columns=['ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c2a044a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ì„¤ë¦½ì—°ë„                 0\n",
       "êµ­ê°€                   0\n",
       "ë¶„ì•¼                 857\n",
       "íˆ¬ìë‹¨ê³„                 0\n",
       "ì§ì› ìˆ˜               174\n",
       "ì¸ìˆ˜ì—¬ë¶€                 0\n",
       "ìƒì¥ì—¬ë¶€                 0\n",
       "ê³ ê°ìˆ˜(ë°±ë§Œëª…)          1320\n",
       "ì´ íˆ¬ìê¸ˆ(ì–µì›)            0\n",
       "ì—°ë§¤ì¶œ(ì–µì›)              0\n",
       "SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)       0\n",
       "ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)         1220\n",
       "ì„±ê³µí™•ë¥                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()\n",
    "# ë¶„ì•¼,ì§ì› ìˆ˜, ê³ ê°ìˆ˜(ë°±ë§Œëª…), ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24436e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)\n",
      "3500-4500    1848\n",
      "4500-6000     679\n",
      "2500-3500     635\n",
      "1500-2500     621\n",
      "6000ì´ìƒ        593\n",
      "Name: count, dtype: int64\n",
      "ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)\n",
      "3500-4500    749\n",
      "4500-6000    292\n",
      "1500-2500    258\n",
      "2500-3500    247\n",
      "6000ì´ìƒ       209\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)' ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
    "def convert_value(value):\n",
    "    if isinstance(value, str):\n",
    "        if 'ì´ìƒ' in value:\n",
    "            return 6000\n",
    "        elif '-' in value:\n",
    "            start, end = value.split('-')\n",
    "            return (float(start) + float(end)) / 2\n",
    "    return float(value)\n",
    "\n",
    "# 2. 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)' ë²”ì£¼í™” í•¨ìˆ˜ ì •ì˜\n",
    "def categorize_value(value):\n",
    "    if value < 2500:\n",
    "        return '1500-2500'\n",
    "    elif value < 3500:\n",
    "        return '2500-3500'\n",
    "    elif value < 4500:\n",
    "        return '3500-4500'\n",
    "    elif value < 6000:\n",
    "        return '4500-6000'\n",
    "    else:\n",
    "        return '6000ì´ìƒ'\n",
    "\n",
    "# 3. ë³µì‚¬í•´ì„œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬\n",
    "train_copy = train.copy()\n",
    "\n",
    "# 4. ê¸°ì—…ê°€ì¹˜ ìˆ«ìë¡œ ë³€í™˜ (NaN ì œì™¸)\n",
    "train_copy.loc[train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].notna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = \\\n",
    "    train_copy.loc[train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].notna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].apply(convert_value)\n",
    "\n",
    "# 5. ê²°ì¸¡ì¹˜ ì œê±°í•œ í•™ìŠµ ë°ì´í„°\n",
    "train_data = train_copy.dropna(subset=['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']).copy()\n",
    "\n",
    "# 6. ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°\n",
    "train_data['ì§ì› ìˆ˜'] = train_data['ì§ì› ìˆ˜'].fillna(train_data['ì§ì› ìˆ˜'].mean())\n",
    "\n",
    "# 7. ëª¨ë¸ í•™ìŠµ\n",
    "features = ['ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì§ì› ìˆ˜', 'ì„¤ë¦½ì—°ë„']\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].astype(float)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 8. NaN ë°ì´í„° ì˜ˆì¸¡\n",
    "test_data = train_copy[train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isna()].copy()\n",
    "test_data['ì§ì› ìˆ˜'] = test_data['ì§ì› ìˆ˜'].fillna(train_data['ì§ì› ìˆ˜'].mean())\n",
    "X_test = test_data[features]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 9. ì˜ˆì¸¡ê°’ ë„£ê¸°\n",
    "train_copy.loc[train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = y_pred\n",
    "\n",
    "# 10. ìˆ«ì â†’ ë²”ì£¼ë¡œ ë‹¤ì‹œ ë³€í™˜\n",
    "train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].astype(float).apply(categorize_value)\n",
    "\n",
    "# âœ… ê²°ê³¼: train_copy ì—ì„œ ê¸°ì—…ê°€ì¹˜ ì»¬ëŸ¼ì´ ë¬¸ìì—´ ë²”ì£¼ë¡œ ì™„ì„±ë¨\n",
    "print(train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].value_counts())\n",
    "\n",
    "train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']\n",
    "\n",
    "# test ë°ì´í„° ë³µì‚¬\n",
    "test_copy = test.copy()\n",
    "\n",
    "# 1. ê¸°ì—…ê°€ì¹˜ ì»¬ëŸ¼ ì „ì²˜ë¦¬\n",
    "def convert_value(value):\n",
    "    if isinstance(value, str):\n",
    "        if 'ì´ìƒ' in value:\n",
    "            return 6000\n",
    "        elif '-' in value:\n",
    "            start, end = value.split('-')\n",
    "            return (float(start) + float(end)) / 2\n",
    "    return float(value)\n",
    "\n",
    "def categorize_value(value):\n",
    "    if value < 2500:\n",
    "        return '1500-2500'\n",
    "    elif value < 3500:\n",
    "        return '2500-3500'\n",
    "    elif value < 4500:\n",
    "        return '3500-4500'\n",
    "    elif value < 6000:\n",
    "        return '4500-6000'\n",
    "    else:\n",
    "        return '6000ì´ìƒ'\n",
    "\n",
    "# 2. ê¸°ì¡´ ê°’ì€ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë°”ê¾¸ê¸°\n",
    "test_copy.loc[test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].notna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = \\\n",
    "    test_copy.loc[test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].notna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].apply(convert_value)\n",
    "\n",
    "# 3. ì˜ˆì¸¡í•´ì•¼ í•  ìƒ˜í”Œ\n",
    "test_nan = test_copy[test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isna()].copy()\n",
    "\n",
    "# 4. ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° (trainì˜ í‰ê· ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n",
    "test_nan['ì§ì› ìˆ˜'] = test_nan['ì§ì› ìˆ˜'].fillna(train_data['ì§ì› ìˆ˜'].mean())\n",
    "\n",
    "# 5. í•„ìš”í•œ ì…ë ¥ê°’ ì„ íƒ\n",
    "X_test = test_nan[['ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì§ì› ìˆ˜', 'ì„¤ë¦½ì—°ë„']]\n",
    "\n",
    "# 6. trainì—ì„œ í•™ìŠµí•œ ëª¨ë¸ë¡œ ì˜ˆì¸¡\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# 7. ì˜ˆì¸¡ ê²°ê³¼ ì±„ì›Œë„£ê¸°\n",
    "test_copy.loc[test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = y_pred_test\n",
    "\n",
    "# 8. ìˆ«ì â†’ ë²”ì£¼ë¡œ ë‹¤ì‹œ ë³€í™˜\n",
    "test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].astype(float).apply(categorize_value)\n",
    "\n",
    "# âœ… ê²°ê³¼ í™•ì¸\n",
    "print(test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].value_counts())\n",
    "\n",
    "test['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f91c4b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_field = train['ë¶„ì•¼'].mode()[0]\n",
    "train['ë¶„ì•¼'] = train['ë¶„ì•¼'].fillna(most_common_field)\n",
    "test['ë¶„ì•¼'] = train['ë¶„ì•¼'].fillna(most_common_field)\n",
    "\n",
    "staff_means_by_field = train.groupby('ë¶„ì•¼')['ì§ì› ìˆ˜'].mean()\n",
    "\n",
    "train['ì§ì› ìˆ˜'] = train.groupby('ë¶„ì•¼')['ì§ì› ìˆ˜'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "def fill_staff_by_field(row):\n",
    "    if pd.isna(row['ì§ì› ìˆ˜']):\n",
    "        return staff_means_by_field.get(row['ë¶„ì•¼'], train['ì§ì› ìˆ˜'].mean())\n",
    "    return row['ì§ì› ìˆ˜']\n",
    "\n",
    "test['ì§ì› ìˆ˜'] = test.apply(fill_staff_by_field, axis=1)\n",
    "\n",
    "valid = train.dropna(subset=['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'])\n",
    "X_train = valid[['ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)']]\n",
    "y_train = valid['ê³ ê°ìˆ˜(ë°±ë§Œëª…)']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡í•  ê²°ì¸¡ì¹˜ í–‰\n",
    "missing = train[train['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].isna()]\n",
    "X_missing = missing[['ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)']]\n",
    "y_pred = model.predict(X_missing)\n",
    "\n",
    "# ì±„ì›Œ ë„£ê¸°\n",
    "train.loc[train['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].isna(), 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] = y_pred\n",
    "\n",
    "missing_test = test[test['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].isna()]\n",
    "X_missing_test = missing_test[['ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)']]\n",
    "y_pred_test = model.predict(X_missing_test)\n",
    "\n",
    "test.loc[test['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].isna(), 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] = y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef3b4b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ì„¤ë¦½ì—°ë„              0\n",
       "êµ­ê°€                0\n",
       "ë¶„ì•¼                0\n",
       "íˆ¬ìë‹¨ê³„              0\n",
       "ì§ì› ìˆ˜              0\n",
       "ì¸ìˆ˜ì—¬ë¶€              0\n",
       "ìƒì¥ì—¬ë¶€              0\n",
       "ê³ ê°ìˆ˜(ë°±ë§Œëª…)          0\n",
       "ì´ íˆ¬ìê¸ˆ(ì–µì›)         0\n",
       "ì—°ë§¤ì¶œ(ì–µì›)           0\n",
       "SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)    0\n",
       "ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)         0\n",
       "ì„±ê³µí™•ë¥               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b71cdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\human\\AppData\\Local\\Temp\\ipykernel_712\\4274075514.py:42: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train[feature] = train[feature].fillna('Missing')\n",
      "C:\\Users\\human\\AppData\\Local\\Temp\\ipykernel_712\\4274075514.py:43: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test[feature] = test[feature].fillna('Missing')\n"
     ]
    }
   ],
   "source": [
    "train['ì„¤ë¦½ì—°ë„'] =train['ì„¤ë¦½ì—°ë„'].astype('object')\n",
    "test['ì„¤ë¦½ì—°ë„'] =test['ì„¤ë¦½ì—°ë„'].astype('object')\n",
    "\n",
    "# # ì„¤ë¦½ì—°ë„ -> íšŒì‚¬ ë‚˜ì´\n",
    "# train['íšŒì‚¬ë‚˜ì´'] = 2025 - train['ì„¤ë¦½ì—°ë„'].astype(int)\n",
    "# test['íšŒì‚¬ë‚˜ì´'] = 2025 - test['ì„¤ë¦½ì—°ë„'].astype(int)\n",
    "\n",
    "# # íˆ¬ìê¸ˆ ëŒ€ë¹„ ì§ì› ìˆ˜\n",
    "# train['íˆ¬ì_ì§ì›_ë¹„ìœ¨'] = train['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] / (train['ì§ì› ìˆ˜'] + 1)\n",
    "# test['íˆ¬ì_ì§ì›_ë¹„ìœ¨'] = test['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] / (test['ì§ì› ìˆ˜'] + 1)\n",
    "\n",
    "def add_engineered_features(df):\n",
    "    df['íˆ¬ìê¸ˆ_ëŒ€ë¹„_ì—°ë§¤ì¶œ'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / (df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] + 1e-6)\n",
    "    df['ê³ ê°ë‹¹_ì—°ë§¤ì¶œ'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / (df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] + 1e-6)\n",
    "    df['ì§ì›ë‹¹_ì—°ë§¤ì¶œ'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / (df['ì§ì› ìˆ˜'] + 1e-6)\n",
    "    df['íˆ¬ìê¸ˆ_ëŒ€ë¹„_SNSì˜í–¥ë ¥'] = df['SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'] / (df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] + 1e-6)\n",
    "    df['íšŒì‚¬ë‚˜ì´'] = 2025 - df['ì„¤ë¦½ì—°ë„'].astype(int)  # íšŒì‚¬ ë‚˜ì´ ì¶”ê°€\n",
    "    df['íˆ¬ì_ì§ì›_ë¹„ìœ¨'] = df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] / (df['ì§ì› ìˆ˜'] + 1)  # íˆ¬ì ëŒ€ë¹„ ì§ì› ë¹„ìœ¨ ì¶”ê°€\n",
    "    return df\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "train = add_engineered_features(train)\n",
    "test = add_engineered_features(test)\n",
    "\n",
    "category_features = ['ì„¤ë¦½ì—°ë„','êµ­ê°€','ë¶„ì•¼','íˆ¬ìë‹¨ê³„','ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']\n",
    "numeric_features = ['ì§ì› ìˆ˜','ê³ ê°ìˆ˜(ë°±ë§Œëª…)','ì´ íˆ¬ìê¸ˆ(ì–µì›)','ì—°ë§¤ì¶œ(ì–µì›)','SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)',\n",
    "                    'íˆ¬ìê¸ˆ_ëŒ€ë¹„_ì—°ë§¤ì¶œ','ê³ ê°ë‹¹_ì—°ë§¤ì¶œ','ì§ì›ë‹¹_ì—°ë§¤ì¶œ','íˆ¬ìê¸ˆ_ëŒ€ë¹„_SNSì˜í–¥ë ¥','íšŒì‚¬ë‚˜ì´','íˆ¬ì_ì§ì›_ë¹„ìœ¨']\n",
    "bool_features = ['ì¸ìˆ˜ì—¬ë¶€','ìƒì¥ì—¬ë¶€']\n",
    "\n",
    "encoders = {}\n",
    "\n",
    "# ë¶ˆë¦¬ì–¸ ê°’ì„ 0ê³¼ 1ë¡œ ë³€í™˜ ('Yes' â†’ 1, 'No' â†’ 0 ìœ¼ë¡œ ë³€í™˜)\n",
    "bool_map = {'Yes': 1, 'No': 0}\n",
    "\n",
    "for feature in bool_features:\n",
    "    train[feature] = train[feature].map(bool_map)\n",
    "    test[feature] = test[feature].map(bool_map)\n",
    "\n",
    "# ë²”ì£¼í˜• ë°ì´í„°ë¥¼ encoding\n",
    "for feature in category_features:\n",
    "    encoders[feature] = LabelEncoder()\n",
    "    train[feature] = train[feature].fillna('Missing')\n",
    "    test[feature] = test[feature].fillna('Missing')\n",
    "    train[feature] = encoders[feature].fit_transform(train[feature])\n",
    "    test[feature] = encoders[feature].transform(test[feature])\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê²°ì¸¡ì¹˜ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "for feature in numeric_features:\n",
    "    mean_value = train[feature].mean()\n",
    "    train[feature] = train[feature].fillna(mean_value)\n",
    "    test[feature] = test[feature].fillna(mean_value)\n",
    "\n",
    "# TabNetìš© ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ë±ìŠ¤(cat_idxs) ë° ì°¨ì›(cat_dims) ì„¤ì •\n",
    "features = [col for col in train.columns if col != 'ì„±ê³µí™•ë¥ ']\n",
    "cat_idxs = [features.index(col) for col in category_features]\n",
    "cat_dims = [train[col].max() + 1 for col in category_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e70e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ì„¤ë¦½ì—°ë„</th>\n",
       "      <th>êµ­ê°€</th>\n",
       "      <th>ë¶„ì•¼</th>\n",
       "      <th>íˆ¬ìë‹¨ê³„</th>\n",
       "      <th>ì§ì› ìˆ˜</th>\n",
       "      <th>ì¸ìˆ˜ì—¬ë¶€</th>\n",
       "      <th>ìƒì¥ì—¬ë¶€</th>\n",
       "      <th>ê³ ê°ìˆ˜(ë°±ë§Œëª…)</th>\n",
       "      <th>ì´ íˆ¬ìê¸ˆ(ì–µì›)</th>\n",
       "      <th>ì—°ë§¤ì¶œ(ì–µì›)</th>\n",
       "      <th>SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)</th>\n",
       "      <th>ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)</th>\n",
       "      <th>ì„±ê³µí™•ë¥ </th>\n",
       "      <th>íˆ¬ìê¸ˆ_ëŒ€ë¹„_ì—°ë§¤ì¶œ</th>\n",
       "      <th>ê³ ê°ë‹¹_ì—°ë§¤ì¶œ</th>\n",
       "      <th>ì§ì›ë‹¹_ì—°ë§¤ì¶œ</th>\n",
       "      <th>íˆ¬ìê¸ˆ_ëŒ€ë¹„_SNSì˜í–¥ë ¥</th>\n",
       "      <th>íšŒì‚¬ë‚˜ì´</th>\n",
       "      <th>íˆ¬ì_ì§ì›_ë¹„ìœ¨</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4126.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3365.0</td>\n",
       "      <td>4764.0</td>\n",
       "      <td>4.71</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.415750</td>\n",
       "      <td>85.071427</td>\n",
       "      <td>1.154629</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>16</td>\n",
       "      <td>0.815362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4167.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>4069.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.068567</td>\n",
       "      <td>3.487500</td>\n",
       "      <td>0.066955</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>2</td>\n",
       "      <td>0.976248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>6453.0</td>\n",
       "      <td>12141.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.881450</td>\n",
       "      <td>224.833329</td>\n",
       "      <td>3.876437</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>7</td>\n",
       "      <td>2.059687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3245.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49.721402</td>\n",
       "      <td>665.0</td>\n",
       "      <td>10547.0</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15.860150</td>\n",
       "      <td>212.121930</td>\n",
       "      <td>3.250231</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>9</td>\n",
       "      <td>0.204868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>829.0</td>\n",
       "      <td>9810.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11.833534</td>\n",
       "      <td>104.361701</td>\n",
       "      <td>4.982224</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>5</td>\n",
       "      <td>0.420812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4841.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>9394.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.243611</td>\n",
       "      <td>104.377777</td>\n",
       "      <td>1.940508</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>4</td>\n",
       "      <td>0.864725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>555.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>796.0</td>\n",
       "      <td>2969.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.729899</td>\n",
       "      <td>80.243241</td>\n",
       "      <td>5.349550</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>5</td>\n",
       "      <td>1.431655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>506.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49.175674</td>\n",
       "      <td>3314.0</td>\n",
       "      <td>4512.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.361497</td>\n",
       "      <td>91.752681</td>\n",
       "      <td>8.916996</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>2</td>\n",
       "      <td>6.536489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1438.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>2395.0</td>\n",
       "      <td>3755.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.567850</td>\n",
       "      <td>70.849055</td>\n",
       "      <td>2.611266</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>24</td>\n",
       "      <td>1.664350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3499.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>903.0</td>\n",
       "      <td>9417.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10.428571</td>\n",
       "      <td>229.682921</td>\n",
       "      <td>2.691340</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>8</td>\n",
       "      <td>0.258000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4376 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ì„¤ë¦½ì—°ë„  êµ­ê°€  ë¶„ì•¼  íˆ¬ìë‹¨ê³„    ì§ì› ìˆ˜  ì¸ìˆ˜ì—¬ë¶€  ìƒì¥ì—¬ë¶€   ê³ ê°ìˆ˜(ë°±ë§Œëª…)  ì´ íˆ¬ìê¸ˆ(ì–µì›)  ì—°ë§¤ì¶œ(ì–µì›)  \\\n",
       "0        8   4   6     2  4126.0     0     0  56.000000     3365.0   4764.0   \n",
       "1       22   5   8     1  4167.0     1     0  80.000000     4069.0    279.0   \n",
       "2       17   6   2     2  3132.0     1     1  54.000000     6453.0  12141.0   \n",
       "3       15   5   4     1  3245.0     1     1  49.721402      665.0  10547.0   \n",
       "4       19   1   5     1  1969.0     0     1  94.000000      829.0   9810.0   \n",
       "...    ...  ..  ..   ...     ...   ...   ...        ...        ...      ...   \n",
       "4371    20   5   7     2  4841.0     1     0  90.000000     4187.0   9394.0   \n",
       "4372    19   2   4     3   555.0     0     1  37.000000      796.0   2969.0   \n",
       "4373    22   3   4     4   506.0     0     1  49.175674     3314.0   4512.0   \n",
       "4374     0   6   0     0  1438.0     0     0  53.000000     2395.0   3755.0   \n",
       "4375    16   5   5     1  3499.0     0     1  41.000000      903.0   9417.0   \n",
       "\n",
       "      SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)  ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)  ì„±ê³µí™•ë¥   íˆ¬ìê¸ˆ_ëŒ€ë¹„_ì—°ë§¤ì¶œ     ê³ ê°ë‹¹_ì—°ë§¤ì¶œ   ì§ì›ë‹¹_ì—°ë§¤ì¶œ  \\\n",
       "0               4.71          2   0.3    1.415750   85.071427  1.154629   \n",
       "1               1.00          1   0.8    0.068567    3.487500  0.066955   \n",
       "2               4.00          2   0.5    1.881450  224.833329  3.876437   \n",
       "3               2.97          2   0.7   15.860150  212.121930  3.250231   \n",
       "4               1.00          0   0.1   11.833534  104.361701  4.982224   \n",
       "...              ...        ...   ...         ...         ...       ...   \n",
       "4371            4.00          0   0.8    2.243611  104.377777  1.940508   \n",
       "4372            3.00          4   0.4    3.729899   80.243241  5.349550   \n",
       "4373            1.47          2   0.6    1.361497   91.752681  8.916996   \n",
       "4374            5.00          3   0.9    1.567850   70.849055  2.611266   \n",
       "4375            5.00          3   0.6   10.428571  229.682921  2.691340   \n",
       "\n",
       "      íˆ¬ìê¸ˆ_ëŒ€ë¹„_SNSì˜í–¥ë ¥  íšŒì‚¬ë‚˜ì´  íˆ¬ì_ì§ì›_ë¹„ìœ¨  \n",
       "0          0.001400    16  0.815362  \n",
       "1          0.000246     2  0.976248  \n",
       "2          0.000620     7  2.059687  \n",
       "3          0.004466     9  0.204868  \n",
       "4          0.001206     5  0.420812  \n",
       "...             ...   ...       ...  \n",
       "4371       0.000955     4  0.864725  \n",
       "4372       0.003769     5  1.431655  \n",
       "4373       0.000444     2  6.536489  \n",
       "4374       0.002088    24  1.664350  \n",
       "4375       0.005537     8  0.258000  \n",
       "\n",
       "[4376 rows x 19 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e22d46f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Fold 1/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mae = 0.20662\n",
      "\n",
      "ğŸ” Fold 2/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_mae = 0.20854\n",
      "\n",
      "ğŸ” Fold 3/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mae = 0.205\n",
      "\n",
      "ğŸ” Fold 4/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_mae = 0.2025\n",
      "\n",
      "ğŸ” Fold 5/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_mae = 0.20667\n",
      "\n",
      "âœ… ëª¨ë“  fold ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# íƒ€ê²Ÿ ì§€ì •\n",
    "target = train['ì„±ê³µí™•ë¥ ']  \n",
    "X = train[features]\n",
    "y = target\n",
    "\n",
    "# KFold ì„¤ì •\n",
    "N_FOLDS = 5\n",
    "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "models = [] # ëª¨ë¸ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\nğŸ” Fold {fold+1}/{N_FOLDS}\")\n",
    "    \n",
    "    X_train = X.iloc[train_idx].values\n",
    "    y_train = y.iloc[train_idx].values.reshape(-1, 1)\n",
    "    \n",
    "    X_valid = X.iloc[valid_idx].values\n",
    "    y_valid = y.iloc[valid_idx].values.reshape(-1, 1)\n",
    "    \n",
    "    # ë¹„ì§€ë„ ì‚¬ì „í•™ìŠµ\n",
    "    print(\"â–¶ Pretraining...\")\n",
    "\n",
    "    pretrainer = TabNetPretrainer(\n",
    "        cat_idxs=cat_idxs,\n",
    "        cat_dims=cat_dims,\n",
    "        seed=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pretrainer.fit(\n",
    "        X_train=X_train,\n",
    "        max_epochs=100,\n",
    "        batch_size=512,\n",
    "        virtual_batch_size=64\n",
    "    )\n",
    "\n",
    "    # ì§€ë„ í•™ìŠµ \n",
    "    print(\"â–¶ Fine-tuning...\")\n",
    "    model = TabNetRegressor(\n",
    "        cat_idxs=cat_idxs,\n",
    "        cat_dims=cat_dims,\n",
    "        seed=42,\n",
    "        verbose=0,\n",
    "        optimizer_fn=torch.optim.AdamW \n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        from_unsupervised=pretrainer,\n",
    "        eval_metric=['mae'],\n",
    "        max_epochs=100,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    # ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ì €ì¥\n",
    "    models.append(model)\n",
    "    cv_scores.append(model.best_cost)\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë“  fold ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5283559d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with fold 1\n",
      "Predict with fold 2\n",
      "Predict with fold 3\n",
      "Predict with fold 4\n",
      "Predict with fold 5\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥ëœ ëª¨ë¸ë“¤ë¡œ ì˜ˆì¸¡\n",
    "predictions_list = []\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "    print(f\"Predict with fold {fold+1}\")\n",
    "    preds = model.predict(test[features].values)\n",
    "    predictions_list.append(preds)\n",
    "\n",
    "# í‰ê·  ì˜ˆì¸¡\n",
    "final_predictions = np.mean(predictions_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29949f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['ì„±ê³µí™•ë¥ '] = final_predictions\n",
    "sample_submission.to_csv('data_files/submission9.csv', index = False, encoding = 'utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
