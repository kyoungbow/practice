{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13ab9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4d7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data_files/train.csv')\n",
    "test = pd.read_csv('data_files/test.csv')\n",
    "sample_submission = pd.read_csv('data_files/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb5f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['ID'], axis = 1)\n",
    "test = test.drop(columns=['ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b71cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ì„¤ë¦½ì—°ë„'] =train['ì„¤ë¦½ì—°ë„'].astype('object')\n",
    "test['ì„¤ë¦½ì—°ë„'] =test['ì„¤ë¦½ì—°ë„'].astype('object')\n",
    "\n",
    "category_features = ['ì„¤ë¦½ì—°ë„','êµ­ê°€','ë¶„ì•¼','íˆ¬ìë‹¨ê³„','ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']\n",
    "numeric_features = ['ì§ì› ìˆ˜','ê³ ê°ìˆ˜(ë°±ë§Œëª…)','ì´ íˆ¬ìê¸ˆ(ì–µì›)','ì—°ë§¤ì¶œ(ì–µì›)','SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)']\n",
    "bool_features = ['ì¸ìˆ˜ì—¬ë¶€','ìƒì¥ì—¬ë¶€']\n",
    "\n",
    "encoders = {}\n",
    "\n",
    "# ë¶ˆë¦¬ì–¸ ê°’ì„ 0ê³¼ 1ë¡œ ë³€í™˜ ('Yes' â†’ 1, 'No' â†’ 0 ìœ¼ë¡œ ë³€í™˜)\n",
    "bool_map = {'Yes': 1, 'No': 0}\n",
    "\n",
    "for feature in bool_features:\n",
    "    train[feature] = train[feature].map(bool_map)\n",
    "    test[feature] = test[feature].map(bool_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e634b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)\n",
      "3500-4500    1848\n",
      "4500-6000     679\n",
      "2500-3500     635\n",
      "1500-2500     621\n",
      "6000ì´ìƒ        593\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)' ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
    "def convert_value(value):\n",
    "    if isinstance(value, str):\n",
    "        if 'ì´ìƒ' in value:\n",
    "            return 6000\n",
    "        elif '-' in value:\n",
    "            start, end = value.split('-')\n",
    "            return (float(start) + float(end)) / 2\n",
    "    return float(value)\n",
    "\n",
    "# 2. 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)' ë²”ì£¼í™” í•¨ìˆ˜ ì •ì˜\n",
    "def categorize_value(value):\n",
    "    if value < 2500:\n",
    "        return '1500-2500'\n",
    "    elif value < 3500:\n",
    "        return '2500-3500'\n",
    "    elif value < 4500:\n",
    "        return '3500-4500'\n",
    "    elif value < 6000:\n",
    "        return '4500-6000'\n",
    "    else:\n",
    "        return '6000ì´ìƒ'\n",
    "\n",
    "# 3. ë³µì‚¬í•´ì„œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬\n",
    "train_copy = train.copy()\n",
    "\n",
    "# 4. ê¸°ì—…ê°€ì¹˜ ìˆ«ìë¡œ ë³€í™˜ (NaN ì œì™¸)\n",
    "train_copy.loc[train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].notna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = \\\n",
    "    train_copy.loc[train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].notna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].apply(convert_value)\n",
    "\n",
    "# 5. ê²°ì¸¡ì¹˜ ì œê±°í•œ í•™ìŠµ ë°ì´í„°\n",
    "train_data = train_copy.dropna(subset=['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']).copy()\n",
    "\n",
    "# 6. ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°\n",
    "train_data['ì§ì› ìˆ˜'] = train_data['ì§ì› ìˆ˜'].fillna(train_data['ì§ì› ìˆ˜'].mean())\n",
    "\n",
    "# 7. ëª¨ë¸ í•™ìŠµ\n",
    "features = ['ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì§ì› ìˆ˜', 'ì„¤ë¦½ì—°ë„']\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].astype(float)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 8. NaN ë°ì´í„° ì˜ˆì¸¡\n",
    "test_data = train_copy[train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isna()].copy()\n",
    "test_data['ì§ì› ìˆ˜'] = test_data['ì§ì› ìˆ˜'].fillna(train_data['ì§ì› ìˆ˜'].mean())\n",
    "X_test = test_data[features]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 9. ì˜ˆì¸¡ê°’ ë„£ê¸°\n",
    "train_copy.loc[train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = y_pred\n",
    "\n",
    "# 10. ìˆ«ì â†’ ë²”ì£¼ë¡œ ë‹¤ì‹œ ë³€í™˜\n",
    "train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].astype(float).apply(categorize_value)\n",
    "\n",
    "# âœ… ê²°ê³¼: train_copy ì—ì„œ ê¸°ì—…ê°€ì¹˜ ì»¬ëŸ¼ì´ ë¬¸ìì—´ ë²”ì£¼ë¡œ ì™„ì„±ë¨\n",
    "print(train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26283687",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = train_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "320a8ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)\n",
      "3500-4500    749\n",
      "4500-6000    292\n",
      "1500-2500    258\n",
      "2500-3500    247\n",
      "6000ì´ìƒ       209\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# test ë°ì´í„° ë³µì‚¬\n",
    "test_copy = test.copy()\n",
    "\n",
    "# 1. ê¸°ì—…ê°€ì¹˜ ì»¬ëŸ¼ ì „ì²˜ë¦¬\n",
    "def convert_value(value):\n",
    "    if isinstance(value, str):\n",
    "        if 'ì´ìƒ' in value:\n",
    "            return 6000\n",
    "        elif '-' in value:\n",
    "            start, end = value.split('-')\n",
    "            return (float(start) + float(end)) / 2\n",
    "    return float(value)\n",
    "\n",
    "def categorize_value(value):\n",
    "    if value < 2500:\n",
    "        return '1500-2500'\n",
    "    elif value < 3500:\n",
    "        return '2500-3500'\n",
    "    elif value < 4500:\n",
    "        return '3500-4500'\n",
    "    elif value < 6000:\n",
    "        return '4500-6000'\n",
    "    else:\n",
    "        return '6000ì´ìƒ'\n",
    "\n",
    "# 2. ê¸°ì¡´ ê°’ì€ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë°”ê¾¸ê¸°\n",
    "test_copy.loc[test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].notna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = \\\n",
    "    test_copy.loc[test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].notna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].apply(convert_value)\n",
    "\n",
    "# 3. ì˜ˆì¸¡í•´ì•¼ í•  ìƒ˜í”Œ\n",
    "test_nan = test_copy[test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isna()].copy()\n",
    "\n",
    "# 4. ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° (trainì˜ í‰ê· ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n",
    "test_nan['ì§ì› ìˆ˜'] = test_nan['ì§ì› ìˆ˜'].fillna(train_data['ì§ì› ìˆ˜'].mean())\n",
    "\n",
    "# 5. í•„ìš”í•œ ì…ë ¥ê°’ ì„ íƒ\n",
    "X_test = test_nan[['ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì§ì› ìˆ˜', 'ì„¤ë¦½ì—°ë„']]\n",
    "\n",
    "# 6. trainì—ì„œ í•™ìŠµí•œ ëª¨ë¸ë¡œ ì˜ˆì¸¡\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# 7. ì˜ˆì¸¡ ê²°ê³¼ ì±„ì›Œë„£ê¸°\n",
    "test_copy.loc[test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = y_pred_test\n",
    "\n",
    "# 8. ìˆ«ì â†’ ë²”ì£¼ë¡œ ë‹¤ì‹œ ë³€í™˜\n",
    "test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].astype(float).apply(categorize_value)\n",
    "\n",
    "# âœ… ê²°ê³¼ í™•ì¸\n",
    "print(test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de531920",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = test_copy['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41b7254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_field = train['ë¶„ì•¼'].mode()[0]\n",
    "train['ë¶„ì•¼'] = train['ë¶„ì•¼'].fillna(most_common_field)\n",
    "test['ë¶„ì•¼'] = train['ë¶„ì•¼'].fillna(most_common_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af731280",
   "metadata": {},
   "outputs": [],
   "source": [
    "staff_means_by_field = train.groupby('ë¶„ì•¼')['ì§ì› ìˆ˜'].mean()\n",
    "\n",
    "train['ì§ì› ìˆ˜'] = train.groupby('ë¶„ì•¼')['ì§ì› ìˆ˜'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "def fill_staff_by_field(row):\n",
    "    if pd.isna(row['ì§ì› ìˆ˜']):\n",
    "        return staff_means_by_field.get(row['ë¶„ì•¼'], train['ì§ì› ìˆ˜'].mean())\n",
    "    return row['ì§ì› ìˆ˜']\n",
    "\n",
    "test['ì§ì› ìˆ˜'] = test.apply(fill_staff_by_field, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd177eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = train.dropna(subset=['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'])\n",
    "X_train = valid[['ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)']]\n",
    "y_train = valid['ê³ ê°ìˆ˜(ë°±ë§Œëª…)']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡í•  ê²°ì¸¡ì¹˜ í–‰\n",
    "missing = train[train['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].isna()]\n",
    "X_missing = missing[['ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)']]\n",
    "y_pred = model.predict(X_missing)\n",
    "\n",
    "# ì±„ì›Œ ë„£ê¸°\n",
    "train.loc[train['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].isna(), 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] = y_pred\n",
    "\n",
    "missing_test = test[test['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].isna()]\n",
    "X_missing_test = missing_test[['ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)']]\n",
    "y_pred_test = model.predict(X_missing_test)\n",
    "\n",
    "test.loc[test['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].isna(), 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] = y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d46f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Fold 1/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_mae = 0.20864\n",
      "\n",
      "ğŸ” Fold 2/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_mae = 0.20425\n",
      "\n",
      "ğŸ” Fold 3/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_mae = 0.20348\n",
      "\n",
      "ğŸ” Fold 4/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_mae = 0.20388\n",
      "\n",
      "ğŸ” Fold 5/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_mae = 0.2066\n",
      "\n",
      "âœ… ëª¨ë“  fold ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "ğŸ”¥ í‰ê·  MAE: 0.2054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------------------------\n",
    "# 1. ë²”ì£¼í˜• ë³€ìˆ˜ ë¼ë²¨ ì¸ì½”ë”©\n",
    "# -------------------------\n",
    "category_features = ['ì„¤ë¦½ì—°ë„', 'êµ­ê°€', 'ë¶„ì•¼', 'íˆ¬ìë‹¨ê³„', 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']  # ìˆ˜ì •í•œ ë¶€ë¶„\n",
    "\n",
    "# LabelEncoderë¥¼ ì»¬ëŸ¼ë³„ë¡œ ë”°ë¡œ ê´€ë¦¬\n",
    "label_encoders = {}\n",
    "\n",
    "# trainê³¼ test ë‘˜ ë‹¤ ë³€í™˜\n",
    "for col in category_features:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.transform(test[col])  # ì£¼ì˜: testëŠ” transformë§Œ\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# -------------------------\n",
    "# 2. Feature ì¤€ë¹„\n",
    "# -------------------------\n",
    "# íƒ€ê²Ÿ ì»¬ëŸ¼ ì œì™¸í•œ feature ë¦¬ìŠ¤íŠ¸\n",
    "features = [col for col in train.columns if col != 'ì„±ê³µí™•ë¥ ']\n",
    "\n",
    "# ë²”ì£¼í˜• featureì˜ index, ì°¨ì›\n",
    "cat_idxs = [features.index(col) for col in category_features]\n",
    "cat_dims = [train[col].nunique() for col in category_features]\n",
    "\n",
    "# X, y ì¤€ë¹„\n",
    "X = train[features]\n",
    "y = train['ì„±ê³µí™•ë¥ ']\n",
    "\n",
    "# -------------------------\n",
    "# 3. KFold + Pretraining + Fine-tuning\n",
    "# -------------------------\n",
    "N_FOLDS = 5\n",
    "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "models = []      # í•™ìŠµëœ ëª¨ë¸ ì €ì¥\n",
    "cv_scores = []   # foldë³„ best cost ì €ì¥\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\nğŸ” Fold {fold+1}/{N_FOLDS}\")\n",
    "\n",
    "    # Foldë³„ ë°ì´í„° ë¶„ë¦¬\n",
    "    X_train = X.iloc[train_idx].values\n",
    "    y_train = y.iloc[train_idx].values.reshape(-1, 1)\n",
    "\n",
    "    X_valid = X.iloc[valid_idx].values\n",
    "    y_valid = y.iloc[valid_idx].values.reshape(-1, 1)\n",
    "\n",
    "    # ë¹„ì§€ë„ ì‚¬ì „í•™ìŠµ\n",
    "    print(\"â–¶ Pretraining...\")\n",
    "    pretrainer = TabNetPretrainer(\n",
    "        cat_idxs=cat_idxs,\n",
    "        cat_dims=cat_dims,\n",
    "        seed=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pretrainer.fit(\n",
    "        X_train=X_train,\n",
    "        max_epochs=100,\n",
    "        batch_size=512,\n",
    "        virtual_batch_size=64\n",
    "    )\n",
    "\n",
    "    # ì§€ë„í•™ìŠµ (Fine-tuning)\n",
    "    print(\"â–¶ Fine-tuning...\")\n",
    "    model = TabNetRegressor(\n",
    "        cat_idxs=cat_idxs,\n",
    "        cat_dims=cat_dims,\n",
    "        seed=42,\n",
    "        verbose=0,\n",
    "        optimizer_fn=torch.optim.AdamW\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        from_unsupervised=pretrainer,\n",
    "        eval_metric=['mae'],\n",
    "        max_epochs=100,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    # ëª¨ë¸ê³¼ score ì €ì¥\n",
    "    models.append(model)\n",
    "    cv_scores.append(model.best_cost)\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë“  fold ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "\n",
    "# ìµœì¢… Cross Validation ì„±ëŠ¥ ì¶œë ¥\n",
    "print(f\"ğŸ”¥ í‰ê·  MAE: {np.mean(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5283559d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with fold 1\n",
      "Predict with fold 2\n",
      "Predict with fold 3\n",
      "Predict with fold 4\n",
      "Predict with fold 5\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥ëœ ëª¨ë¸ë“¤ë¡œ ì˜ˆì¸¡\n",
    "predictions_list = []\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "    print(f\"Predict with fold {fold+1}\")\n",
    "    preds = model.predict(test[features].values)\n",
    "    predictions_list.append(preds)\n",
    "\n",
    "# í‰ê·  ì˜ˆì¸¡\n",
    "final_predictions = np.mean(predictions_list, axis=0)\n",
    "\n",
    "# (ì„ íƒ) 0~1 ë²”ìœ„ë¡œ í´ë¦¬í•‘\n",
    "final_predictions = np.clip(final_predictions, 0, 1)\n",
    "\n",
    "sample_submission['ì„±ê³µí™•ë¥ '] = final_predictions\n",
    "sample_submission.to_csv('data_files/submission7.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29949f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with fold 1\n",
      "Predict with fold 2\n",
      "Predict with fold 3\n",
      "Predict with fold 4\n",
      "Predict with fold 5\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥ëœ ëª¨ë¸ë“¤ë¡œ ì˜ˆì¸¡\n",
    "predictions_list = []\n",
    "fold_scores = []\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "    print(f\"Predict with fold {fold+1}\")\n",
    "    preds = model.predict(test[features].values)\n",
    "    predictions_list.append(preds)\n",
    "    fold_scores.append(model.best_cost)  # foldë§ˆë‹¤ validation MAE ê¸°ë¡\n",
    "\n",
    "# fold ë³„ MAEê°€ ì‘ì„ìˆ˜ë¡ weightë¥¼ í¬ê²Œ\n",
    "fold_scores = np.array(fold_scores)\n",
    "fold_weights = 1 / (fold_scores + 1e-6)  # 0 ë‚˜ëˆ„ê¸° ë°©ì§€ìš© 1e-6 ì¶”ê°€\n",
    "fold_weights = fold_weights / fold_weights.sum()  # í•©ì´ 1ì´ ë˜ê²Œ ì •ê·œí™”\n",
    "\n",
    "# ê°€ì¤‘ í‰ê· \n",
    "final_predictions = np.average(predictions_list, axis=0, weights=fold_weights)\n",
    "\n",
    "# 0~1 ë²”ìœ„ë¡œ í´ë¦¬í•‘\n",
    "final_predictions = np.clip(final_predictions, 0, 1)\n",
    "\n",
    "# ì €ì¥\n",
    "sample_submission['ì„±ê³µí™•ë¥ '] = final_predictions\n",
    "sample_submission.to_csv('data_files/submission8.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
