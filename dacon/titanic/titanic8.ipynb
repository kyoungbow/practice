{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a13ab9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c4d7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data_files/train.csv')\n",
    "test = pd.read_csv('../data_files/test.csv')\n",
    "sample_submission = pd.read_csv('../data_files/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfb5f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['ID'], axis = 1)\n",
    "test = test.drop(columns=['ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d06e6a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 백억단위 실수로 만들기\n",
    "\n",
    "def convert_value(value):\n",
    "    if isinstance(value, str):\n",
    "        if '이상' in value:\n",
    "            return 6000\n",
    "        elif '-' in value:\n",
    "            start, end = value.split('-')\n",
    "            return (float(start) + float(end)) / 2\n",
    "    return float(value)\n",
    "\n",
    "# 1. train 데이터 가공\n",
    "train = train.copy()\n",
    "train['기업가치(백억원)'] = train['기업가치(백억원)'].apply(convert_value)\n",
    "\n",
    "train_data = train.dropna(subset=['기업가치(백억원)'])\n",
    "X = train_data[['총 투자금(억원)', '연매출(억원)', '직원 수']].copy()\n",
    "X['설립연도'] = train_data['설립연도'].astype(int)\n",
    "y = train_data['기업가치(백억원)']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# 2. 결측치 채우기\n",
    "train_nan = train[train['기업가치(백억원)'].isna()].copy()\n",
    "train_nan['직원 수'] = train_nan['직원 수'].fillna(train_data['직원 수'].mean())\n",
    "\n",
    "X_test = train_nan[['총 투자금(억원)', '연매출(억원)', '직원 수']].copy()\n",
    "X_test['설립연도'] = train_nan['설립연도'].astype(int)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "train.loc[train['기업가치(백억원)'].isna(), '기업가치(백억원)'] = y_pred\n",
    "\n",
    "# 3. test 데이터도 동일하게\n",
    "test = test.copy()\n",
    "test['기업가치(백억원)'] = test['기업가치(백억원)'].apply(convert_value)\n",
    "\n",
    "test_nan = test[test['기업가치(백억원)'].isna()].copy()\n",
    "test_nan['직원 수'] = test_nan['직원 수'].fillna(train['직원 수'].mean())\n",
    "\n",
    "X_test = test_nan[['총 투자금(억원)', '연매출(억원)', '직원 수']].copy()\n",
    "X_test['설립연도'] = test_nan['설립연도'].astype(int)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "test.loc[test['기업가치(백억원)'].isna(), '기업가치(백억원)'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68712604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2000.000000\n",
       "1       4122.880997\n",
       "2       6000.000000\n",
       "3       2000.000000\n",
       "4       4111.128008\n",
       "           ...     \n",
       "1750    2000.000000\n",
       "1751    5250.000000\n",
       "1752    2000.000000\n",
       "1753    5250.000000\n",
       "1754    3954.796522\n",
       "Name: 기업가치(백억원), Length: 1755, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train['기업가치(백억원)']\n",
    "\n",
    "test['기업가치(백억원)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db9cf458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Series A', 'Seed', 'Series C', 'Series B', 'IPO'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['투자단계'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9863cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = {'Series A':1, 'Seed':0, 'Series C':2, 'Series B':3, 'IPO':4}\n",
    "train['투자단계'] = train['투자단계'].map(stat)\n",
    "test['투자단계'] = test['투자단계'].map(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b71cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 범주형, 수치형, 불리언 feature 정의\n",
    "category_features = ['국가', '분야']\n",
    "numeric_features = ['투자단계','직원 수', '고객수(백만명)', '총 투자금(억원)', '연매출(억원)', \n",
    "                    'SNS 팔로워 수(백만명)', '기업가치(백억원)', '회사나이']\n",
    "bool_features = ['인수여부', '상장여부']\n",
    "\n",
    "encoders = {}\n",
    "\n",
    "# 1. 회사나이(2025 - 설립연도) 계산\n",
    "train['회사나이'] = 2025 - train['설립연도'].astype(float)\n",
    "test['회사나이'] = 2025 - test['설립연도'].astype(float)\n",
    "\n",
    "# 2. 불리언 값을 0과 1로 변환 ('Yes' → 1, 'No' → 0)\n",
    "bool_map = {'Yes': 1, 'No': 0}\n",
    "for feature in bool_features:\n",
    "    train[feature] = train[feature].fillna('No').map(bool_map)\n",
    "    test[feature] = test[feature].fillna('No').map(bool_map)\n",
    "\n",
    "# 3. 범주형 데이터를 Label Encoding\n",
    "for feature in category_features:\n",
    "    encoders[feature] = LabelEncoder()\n",
    "    train[feature] = train[feature].fillna('Missing')\n",
    "    test[feature] = test[feature].fillna('Missing')\n",
    "    train[feature] = encoders[feature].fit_transform(train[feature])\n",
    "    test[feature] = encoders[feature].transform(test[feature])\n",
    "\n",
    "# 4. 수치형 변수 결측치를 평균값으로 대체\n",
    "for feature in numeric_features:\n",
    "    mean_value = train[feature].mean()\n",
    "    train[feature] = train[feature].fillna(mean_value)\n",
    "    test[feature] = test[feature].fillna(mean_value)\n",
    "\n",
    "# 5. TabNet용 범주형 변수 인덱스(cat_idxs) 및 차원(cat_dims) 설정\n",
    "features = [col for col in train.columns if col != '성공확률']\n",
    "cat_idxs = [features.index(col) for col in category_features]\n",
    "cat_dims = [train[col].max() + 1 for col in category_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e22d46f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Fold 1/5\n",
      "▶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_mae = 0.20431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Fold 2/5\n",
      "▶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_mae = 0.20466\n",
      "\n",
      "🔁 Fold 3/5\n",
      "▶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mae = 0.20309\n",
      "\n",
      "🔁 Fold 4/5\n",
      "▶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_mae = 0.20275\n",
      "\n",
      "🔁 Fold 5/5\n",
      "▶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_mae = 0.20557\n",
      "\n",
      "✅ 모든 fold 모델 학습 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# 타겟 지정\n",
    "target = train['성공확률']  \n",
    "X = train[features]\n",
    "y = target\n",
    "\n",
    "# KFold 설정\n",
    "N_FOLDS = 5\n",
    "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "models = [] # 모델 저장 리스트\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\n🔁 Fold {fold+1}/{N_FOLDS}\")\n",
    "    \n",
    "    X_train = X.iloc[train_idx].values\n",
    "    y_train = y.iloc[train_idx].values.reshape(-1, 1)\n",
    "    \n",
    "    X_valid = X.iloc[valid_idx].values\n",
    "    y_valid = y.iloc[valid_idx].values.reshape(-1, 1)\n",
    "    \n",
    "    # 비지도 사전학습\n",
    "    print(\"▶ Pretraining...\")\n",
    "\n",
    "    pretrainer = TabNetPretrainer(\n",
    "        cat_idxs=cat_idxs,\n",
    "        cat_dims=cat_dims,\n",
    "        seed=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pretrainer.fit(\n",
    "        X_train=X_train,\n",
    "        max_epochs=100,\n",
    "        batch_size=512,\n",
    "        virtual_batch_size=64\n",
    "    )\n",
    "\n",
    "    # 지도 학습 \n",
    "    print(\"▶ Fine-tuning...\")\n",
    "    model = TabNetRegressor(\n",
    "        cat_idxs=cat_idxs,\n",
    "        cat_dims=cat_dims,\n",
    "        seed=42,\n",
    "        verbose=0,\n",
    "        optimizer_fn=torch.optim.AdamW \n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        from_unsupervised=pretrainer,\n",
    "        eval_metric=['mae'],\n",
    "        max_epochs=100,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    # 모델을 메모리에 저장\n",
    "    models.append(model)\n",
    "    cv_scores.append(model.best_cost)\n",
    "\n",
    "print(\"\\n✅ 모든 fold 모델 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5283559d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with fold 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with fold 2\n",
      "Predict with fold 3\n",
      "Predict with fold 4\n",
      "Predict with fold 5\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델들로 예측\n",
    "predictions_list = []\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "    print(f\"Predict with fold {fold+1}\")\n",
    "    preds = model.predict(test[features].values)\n",
    "    predictions_list.append(preds)\n",
    "\n",
    "# 평균 예측\n",
    "final_predictions = np.mean(predictions_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29949f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['성공확률'] = final_predictions\n",
    "sample_submission.to_csv('../data_files/submission11.csv', index = False, encoding = 'utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
