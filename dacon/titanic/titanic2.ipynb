{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a13ab9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-tabnet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2c4d7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data_files/train.csv')\n",
    "test = pd.read_csv('data_files/test.csv')\n",
    "sample_submission = pd.read_csv('data_files/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dfb5f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['ID'], axis = 1)\n",
    "test = test.drop(columns=['ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "625a5633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ì„¤ë¦½ì—°ë„', 'êµ­ê°€', 'ë¶„ì•¼', 'íˆ¬ìë‹¨ê³„', 'ì§ì› ìˆ˜', 'ì¸ìˆ˜ì—¬ë¶€', 'ìƒì¥ì—¬ë¶€', 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)',\n",
       "       'ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ì—°ë§¤ì¶œ(ì–µì›)', 'SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)', 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)', 'ì„±ê³µí™•ë¥ '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8b71cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ì„¤ë¦½ì—°ë„'] =train['ì„¤ë¦½ì—°ë„'].astype('object')\n",
    "test['ì„¤ë¦½ì—°ë„'] =test['ì„¤ë¦½ì—°ë„'].astype('object')\n",
    "\n",
    "category_features = ['ì„¤ë¦½ì—°ë„','êµ­ê°€','ë¶„ì•¼','íˆ¬ìë‹¨ê³„','ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']\n",
    "numeric_features = ['ì§ì› ìˆ˜','ê³ ê°ìˆ˜(ë°±ë§Œëª…)','ì´ íˆ¬ìê¸ˆ(ì–µì›)','ì—°ë§¤ì¶œ(ì–µì›)','SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)']\n",
    "bool_features = ['ì¸ìˆ˜ì—¬ë¶€','ìƒì¥ì—¬ë¶€']\n",
    "\n",
    "encoders = {}\n",
    "\n",
    "# ë¶ˆë¦¬ì–¸ ê°’ì„ 0ê³¼ 1ë¡œ ë³€í™˜ ('Yes' â†’ 1, 'No' â†’ 0 ìœ¼ë¡œ ë³€í™˜)\n",
    "bool_map = {'Yes': 1, 'No': 0}\n",
    "\n",
    "for feature in bool_features:\n",
    "    train[feature] = train[feature].map(bool_map)\n",
    "    test[feature] = test[feature].map(bool_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7246965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '2500-3500', '3500-4500', '1500-2500', '4500-6000', '6000ì´ìƒ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ca0de451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\human\\AppData\\Local\\Temp\\ipykernel_2336\\1034075408.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['ì§ì› ìˆ˜'] = test_data['ì§ì› ìˆ˜'].fillna(train_data['ì§ì› ìˆ˜'].mean())\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = train.dropna(subset=['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'])\n",
    "def convert_value(value):\n",
    "    # 'ì´ìƒ'ì´ í¬í•¨ë˜ë©´ 6000ìœ¼ë¡œ ì²˜ë¦¬\n",
    "    if isinstance(value, str):\n",
    "        if 'ì´ìƒ' in value:\n",
    "            return 6000  # 6000ì´ìƒ -> 6000ìœ¼ë¡œ ì²˜ë¦¬\n",
    "        elif '-' in value:  # ë²”ìœ„ê°’ ì²˜ë¦¬\n",
    "            start, end = value.split('-')\n",
    "            return (float(start) + float(end)) / 2  # ë²”ìœ„ì˜ í‰ê· ê°’ ì²˜ë¦¬\n",
    "    return float(value)  # ê·¸ ì™¸ ìˆ«ìê°’ ê·¸ëŒ€ë¡œ ë°˜í™˜\n",
    "\n",
    "# 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'ì— ì ìš©\n",
    "train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].apply(convert_value)\n",
    "\n",
    "X = train_data[['ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì§ì› ìˆ˜', 'ì„¤ë¦½ì—°ë„']]  # í•„ìš”í•œ ì…ë ¥ê°’\n",
    "y = train_data['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']  # ì˜ˆì¸¡í•  ê°’\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "test_data = train[train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isna()]\n",
    "test_data['ì§ì› ìˆ˜'] = test_data['ì§ì› ìˆ˜'].fillna(train_data['ì§ì› ìˆ˜'].mean())\n",
    "X_test = test_data[['ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì§ì› ìˆ˜', 'ì„¤ë¦½ì—°ë„']]\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 5. ì˜ˆì¸¡í•œ ê°’ ì±„ìš°ê¸°\n",
    "train.loc[train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = y_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cecfd1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_value(x):\n",
    "    if 2500 <= x < 3500:\n",
    "        return '2500-3500'\n",
    "    elif 3500 <= x < 4500:\n",
    "        return '3500-4500'\n",
    "    elif 1500 <= x < 2500:\n",
    "        return '1500-2500'\n",
    "    elif 4500 <= x < 6000:\n",
    "        return '4500-6000'\n",
    "    elif x >= 6000:\n",
    "        return '6000ì´ìƒ'\n",
    "\n",
    "# ì ìš©\n",
    "train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].apply(categorize_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "60569e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3500-4500\n",
       "1       2500-3500\n",
       "2       3500-4500\n",
       "3       3500-4500\n",
       "4       1500-2500\n",
       "          ...    \n",
       "4371    1500-2500\n",
       "4372       6000ì´ìƒ\n",
       "4373    3500-4500\n",
       "4374    4500-6000\n",
       "4375    4500-6000\n",
       "Name: ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›), Length: 4376, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123a58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\human\\AppData\\Local\\Temp\\ipykernel_2336\\4259071425.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['ì§ì› ìˆ˜'] = test_data['ì§ì› ìˆ˜'].fillna(train['ì§ì› ìˆ˜'].mean())\n"
     ]
    }
   ],
   "source": [
    "test ë°ì´í„°í”„ë ˆì„ì—ì„œë„ ë™ì¼í•œ ì „ì²˜ë¦¬ ì§„í–‰\n",
    "\n",
    "test_data = test.dropna(subset=['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'])\n",
    "\n",
    "# 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'ì— ë²”ìœ„ë‚˜ ì¡°ê±´ ì²˜ë¦¬ ì ìš©\n",
    "\n",
    "def convert_value(value):\n",
    "    # 'ì´ìƒ'ì´ í¬í•¨ë˜ë©´ 6000ìœ¼ë¡œ ì²˜ë¦¬\n",
    "    if isinstance(value, str):\n",
    "        if 'ì´ìƒ' in value:\n",
    "            return 6000  # 6000ì´ìƒ -> 6000ìœ¼ë¡œ ì²˜ë¦¬\n",
    "        elif '-' in value:  # ë²”ìœ„ê°’ ì²˜ë¦¬\n",
    "            start, end = value.split('-')\n",
    "            return (float(start) + float(end)) / 2  # ë²”ìœ„ì˜ í‰ê· ê°’ ì²˜ë¦¬\n",
    "    return float(value)  # ê·¸ ì™¸ ìˆ«ìê°’ ê·¸ëŒ€ë¡œ ë°˜í™˜\n",
    "\n",
    "test['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = test['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].apply(convert_value)\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ (train ë°ì´í„°ì—ì„œ)\n",
    "X_train = test[['ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì§ì› ìˆ˜', 'ì„¤ë¦½ì—°ë„']]  # í•„ìš”í•œ ì…ë ¥ê°’\n",
    "\n",
    "\n",
    "# test ë°ì´í„°ì—ì„œ 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'ì´ NaNì¸ í–‰ ì°¾ê¸°\n",
    "test_data = test[test['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isna()]\n",
    "\n",
    "# 'ì§ì› ìˆ˜' NaN ê°’ ì±„ìš°ê¸° (trainì˜ í‰ê· ê°’ìœ¼ë¡œ)\n",
    "test_data['ì§ì› ìˆ˜'] = test_data['ì§ì› ìˆ˜'].fillna(train['ì§ì› ìˆ˜'].mean())\n",
    "\n",
    "# ì˜ˆì¸¡ì„ ìœ„í•œ X_test\n",
    "X_test = test_data[['ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì§ì› ìˆ˜', 'ì„¤ë¦½ì—°ë„']]\n",
    "\n",
    "# ì˜ˆì¸¡ê°’ ê³„ì‚°\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ì˜ˆì¸¡í•œ ê°’ ì±„ìš°ê¸°\n",
    "test.loc[test['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isna(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "559c7eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ì„¤ë¦½ì—°ë„         0\n",
       "êµ­ê°€           0\n",
       "ë¶„ì•¼           0\n",
       "íˆ¬ìë‹¨ê³„         0\n",
       "ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[category_features].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9b868658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\human\\AppData\\Local\\Temp\\ipykernel_2336\\4196255663.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train[feature] = train[feature].fillna('Missing')\n",
      "C:\\Users\\human\\AppData\\Local\\Temp\\ipykernel_2336\\4196255663.py:5: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test[feature] = test[feature].fillna('Missing')\n"
     ]
    }
   ],
   "source": [
    "# ë²”ì£¼í˜• ë°ì´í„°ë¥¼ encoding\n",
    "for feature in category_features:\n",
    "    encoders[feature] = LabelEncoder()\n",
    "    train[feature] = train[feature].fillna('Missing')\n",
    "    test[feature] = test[feature].fillna('Missing')\n",
    "    train[feature] = encoders[feature].fit_transform(train[feature])\n",
    "    test[feature] = encoders[feature].transform(test[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8906372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê²°ì¸¡ì¹˜ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "for feature in numeric_features:\n",
    "    mean_value = train[feature].mean()\n",
    "    train[feature] = train[feature].fillna(mean_value)\n",
    "    test[feature] = test[feature].fillna(mean_value)\n",
    "\n",
    "# TabNetìš© ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ë±ìŠ¤(cat_idxs) ë° ì°¨ì›(cat_dims) ì„¤ì •\n",
    "features = [col for col in train.columns if col != 'ì„±ê³µí™•ë¥ ']\n",
    "cat_idxs = [features.index(col) for col in category_features]\n",
    "cat_dims = [train[col].max() + 1 for col in category_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e22d46f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Fold 1/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_mae = 0.20383\n",
      "\n",
      "ğŸ” Fold 2/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_mae = 0.20559\n",
      "\n",
      "ğŸ” Fold 3/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_mae = 0.20301\n",
      "\n",
      "ğŸ” Fold 4/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_mae = 0.20514\n",
      "\n",
      "ğŸ” Fold 5/5\n",
      "â–¶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_mae = 0.20454\n",
      "\n",
      "âœ… ëª¨ë“  fold ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\miniconda3\\envs\\conda-env-311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# íƒ€ê²Ÿ ì§€ì •\n",
    "target = train['ì„±ê³µí™•ë¥ ']  \n",
    "X = train[features]\n",
    "y = target\n",
    "\n",
    "# KFold ì„¤ì •\n",
    "N_FOLDS = 5\n",
    "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "models = [] # ëª¨ë¸ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\nğŸ” Fold {fold+1}/{N_FOLDS}\")\n",
    "    \n",
    "    X_train = X.iloc[train_idx].values\n",
    "    y_train = y.iloc[train_idx].values.reshape(-1, 1)\n",
    "    \n",
    "    X_valid = X.iloc[valid_idx].values\n",
    "    y_valid = y.iloc[valid_idx].values.reshape(-1, 1)\n",
    "    \n",
    "    # ë¹„ì§€ë„ ì‚¬ì „í•™ìŠµ\n",
    "    print(\"â–¶ Pretraining...\")\n",
    "\n",
    "    pretrainer = TabNetPretrainer(\n",
    "        cat_idxs=cat_idxs,\n",
    "        cat_dims=cat_dims,\n",
    "        seed=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pretrainer.fit(\n",
    "        X_train=X_train,\n",
    "        max_epochs=100,\n",
    "        batch_size=512,\n",
    "        virtual_batch_size=64\n",
    "    )\n",
    "\n",
    "    # ì§€ë„ í•™ìŠµ \n",
    "    print(\"â–¶ Fine-tuning...\")\n",
    "    model = TabNetRegressor(\n",
    "        cat_idxs=cat_idxs,\n",
    "        cat_dims=cat_dims,\n",
    "        seed=42,\n",
    "        verbose=0,\n",
    "        optimizer_fn=torch.optim.AdamW \n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        from_unsupervised=pretrainer,\n",
    "        eval_metric=['mae'],\n",
    "        max_epochs=100,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    # ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ì €ì¥\n",
    "    models.append(model)\n",
    "    cv_scores.append(model.best_cost)\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë“  fold ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5283559d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with fold 1\n",
      "Predict with fold 2\n",
      "Predict with fold 3\n",
      "Predict with fold 4\n",
      "Predict with fold 5\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥ëœ ëª¨ë¸ë“¤ë¡œ ì˜ˆì¸¡\n",
    "predictions_list = []\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "    print(f\"Predict with fold {fold+1}\")\n",
    "    preds = model.predict(test[features].values)\n",
    "    predictions_list.append(preds)\n",
    "\n",
    "# í‰ê·  ì˜ˆì¸¡\n",
    "final_predictions = np.mean(predictions_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29949f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['ì„±ê³µí™•ë¥ '] = final_predictions\n",
    "# sample_submission.to_csv('data_files/submission5.csv', index = False, encoding = 'utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
